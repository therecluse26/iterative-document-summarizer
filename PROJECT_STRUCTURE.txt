AI Sliding Context Summarizer - Complete File Structure
========================================================

ai-sliding-context-summarizer/
│
├── baml/                          # BAML definitions (legacy location)
│   ├── schemas.baml              # Type definitions for structured outputs
│   ├── clients.baml              # LLM client configurations
│   └── functions.baml            # BAML function definitions
│
├── baml_src/                      # BAML source files (primary location)
│   ├── baml.config               # BAML project configuration
│   ├── schemas.baml              # Type definitions (SummarySchema, AnalysisReport)
│   ├── clients.baml              # LLM clients (Haiku, Sonnet, GPT variants)
│   └── functions.baml            # Functions (SummarizeChunk, MergeSummaries, AnalyzeSummary)
│
├── baml_client/                   # Auto-generated Python client (created by baml-cli)
│   └── [Generated code]          # DO NOT EDIT - regenerate with baml-cli
│
├── src/                           # Python source code
│   └── orchestrator.py           # Main pipeline orchestration script
│
├── summaries/                     # Output directory for intermediate summaries
│   └── [session_id]/             # Each run creates timestamped subdirectory
│       ├── chunk_*.json          # Individual chunk summaries
│       ├── merge_*.json          # Hierarchical merge results
│       └── final_analysis.json   # Complete analysis output
│
├── logs/                          # Session logs
│   └── [session_id].log          # Detailed processing log for each run
│
├── config.json                    # Configuration (chunk size, overlap, models)
├── requirements.txt               # Python dependencies
├── .env                          # Environment variables (API keys) - DO NOT COMMIT
├── .env.example                  # Example environment file template
├── .gitignore                    # Git ignore rules
│
├── setup.sh                      # Automated setup script
├── example_input.txt             # Sample document for testing
│
├── README.md                     # Complete documentation and usage guide
├── QUICKSTART.md                 # 5-minute quick start guide
├── ARCHITECTURE.md               # Detailed technical architecture
└── PROJECT_STRUCTURE.txt         # This file

Key Files Description
=====================

BAML Files:
-----------
schemas.baml      - Defines Entity, KeyFact, Relationship, SummarySchema, AnalysisReport
clients.baml      - Configures Haiku (summarizer), Sonnet (analyzer), GPT alternatives
functions.baml    - Implements SummarizeChunk, MergeSummaries, AnalyzeSummary

Python Files:
-------------
orchestrator.py   - Main script with DocumentChunker and SummarizationPipeline classes

Configuration:
--------------
config.json       - Runtime configuration (chunk_size: 2000, overlap: 200)
.env              - API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY)
baml.config       - BAML code generation settings

Documentation:
--------------
README.md         - Full project documentation with installation, usage, examples
QUICKSTART.md     - Fast-track setup and first run guide
ARCHITECTURE.md   - Technical deep-dive into system design and data flow

Utilities:
----------
setup.sh          - One-command setup script (creates venv, installs deps, generates client)
example_input.txt - 2,500-word AI healthcare article for testing

Workflow Overview
=================

1. Setup:
   ./setup.sh                                    # Automated setup
   # OR
   baml-cli generate --from ./baml_src --output ./baml_client

2. Run:
   python src/orchestrator.py example_input.txt output.md

3. Output:
   - output.md                                   # Final human-readable report
   - summaries/[timestamp]/                      # All intermediate JSON summaries
   - logs/[timestamp].log                        # Detailed processing log

Extension Points
================

To modify prompts:
  → Edit baml_src/functions.baml
  → Run: baml-cli generate --from ./baml_src --output ./baml_client

To change models:
  → Edit client references in baml_src/functions.baml
  → Regenerate with baml-cli

To adjust chunking:
  → Edit config.json (chunk_size, overlap, merge_batch_size)

To add new output formats:
  → Extend orchestrator.py with new generator methods

Dependencies
============

Python packages (requirements.txt):
  - baml-py         # BAML Python client library
  - tiktoken        # Token counting
  - pydantic        # Schema validation

External tools:
  - baml-cli        # BAML code generator (npm install -g @boundaryml/baml)
  - Python 3.9+     # Required Python version

API Requirements:
  - Anthropic API key (for Claude models)
  - OpenAI API key (optional, for GPT models)

Generated Files (DO NOT EDIT)
==============================

baml_client/      # Auto-generated by baml-cli - regenerate instead of editing
summaries/        # Runtime output - safe to delete between runs
logs/             # Runtime logs - safe to delete

Files to Customize
==================

baml_src/*.baml   # Modify prompts, schemas, add functions
config.json       # Adjust chunking parameters
orchestrator.py   # Extend pipeline, add features
.env              # Add your API keys

Version Information
===================

BAML version: 0.1.0+
Python: 3.9+
Models: Claude 3 Haiku, Claude 3.5 Sonnet (or GPT-4o-mini, GPT-4o)

